{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_script_path = \"./fine_tuned.pt\"\n",
    "model_script_path = \"./general.pt\"\n",
    "model_script_path = \"./piezo_only.pt\"\n",
    "\n",
    "model = torch.jit.load(model_script_path).cuda()\n",
    "\n",
    "folder = './roughness_dataset/opus/stereo/'\n",
    "contact_threshold = 0.005\n",
    "\n",
    "smooth_stones_test = [21]\n",
    "rough_stones_test = [22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file(folder, file, label, x):\n",
    "    \n",
    "    wave, _ = torchaudio.load(folder+file)\n",
    "    wave = torchaudio.functional.resample(wave, RESAMPLE_FACTOR, 1)\n",
    "\n",
    "    parts = cut_stepped(wave)\n",
    "    loudness = parts[:,0].abs().mean(dim=1)\n",
    "    loud_parts_mask = loudness > contact_threshold\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        pred = model(parts.cuda())[:,2].exp()\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    \n",
    "    if label == 1:\n",
    "        off = (label - pred)[loud_parts_mask]\n",
    "        if off.shape[0] == 0:\n",
    "            print(file+\": no chunks above threshold!\")\n",
    "            return 0, 0, 0, label, x\n",
    "        loss = off.abs().mean().item()\n",
    "        acc = float((off <= 0.5).sum()) / float(off.shape[0])\n",
    "    \n",
    "    else:\n",
    "        off = torch.abs((label - pred)[loud_parts_mask])\n",
    "        if off.shape[0] == 0:\n",
    "            print(file+\": no chunks above threshold!\")\n",
    "            return 0, 0, 0, label, x\n",
    "        loss = off.abs().mean().item()\n",
    "        acc = float((off < 0.5).sum()) / float(off.shape[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(17,5))\n",
    "    \n",
    "   \n",
    "    \n",
    "    if label == 0:\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        color = \"orange\"\n",
    "    \n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    #ax.plot(pred[loud_parts_mask].cpu().numpy(),color=color)\n",
    "    ax.plot(pred.cpu().numpy(),color=color)\n",
    "    ax.set_title(file+\" (Roughness confidence)\")\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "    #ax.plot(wave[0,511:][loud_parts_mask].cpu().numpy(),color=color)\n",
    "    ax.plot(wave[0,511:].cpu().numpy(),color=color)\n",
    "    ax.set_title(file+\" (Audio)\")\n",
    "    ax.set_ylim(-1,1)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    print(file+\"    \\tLoss: \"+str(np.round(loss,4))+\" \\tAccuracy: \"+str(np.round(acc,4))+\" \\tUsed chunks: \"+str(int(loud_parts_mask.float().sum().item())))\n",
    "    \n",
    "    return loss, acc, float(off.shape[0]), label, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_files(folder,file_ids,label):\n",
    "    print(\"\\n#################################################\\nTesting \"+(\"smooth\" if label==0 else \"rough\")+\" objects:\\n\")\n",
    "    \n",
    "    total_counts = []\n",
    "    avg_loss = []\n",
    "    avg_acc = []\n",
    "        \n",
    "    for x in file_ids:\n",
    "        if x < 10:\n",
    "            x = \"0\"+str(x)\n",
    "        else:\n",
    "            x = str(x)\n",
    "        \n",
    "        print(\"Testing object '\"+folder+str(x)+\"_' with label '\"+str(label)+\"'...\")\n",
    "        \n",
    "        results = []\n",
    "        results.append(test_file(folder,x+'_long_light.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_long_medium.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_long_loud.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_short_light.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_short_medium.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_short_loud.wav',label,int(x)))\n",
    "        results.append(test_file(folder,x+'_wiggle.wav',label,int(x)))\n",
    "\n",
    "        res = np.array(results)\n",
    "        \n",
    "        avg_loss.append(np.sum(res[:,0]*(res[:,2]/np.sum(res[:,2]))))\n",
    "        avg_acc.append(np.sum(res[:,1]*(res[:,2]/np.sum(res[:,2]))))\n",
    "        total_counts.append(int(np.sum(res[:,2])))\n",
    "        \n",
    "        print(\"---\")\n",
    "        print(\"Avg. loss of object '\"+str(x)+\"': \\t\"+str(np.round(avg_loss[-1],4)))\n",
    "        print(\"Avg. accuracy of object '\"+str(x)+\"': \\t\"+str(np.round(avg_acc[-1],4)))\n",
    "        print(\"Total chunks of object '\"+str(x)+\"': \\t\"+str(total_counts[-1])+\"\\n\")\n",
    "    \n",
    "    avg_loss = np.asarray(avg_loss)\n",
    "    avg_acc = np.asarray(avg_acc)\n",
    "    total_counts = np.asarray(total_counts)\n",
    "    avg_loss_mean = np.sum(avg_loss*(total_counts/np.sum(total_counts)))\n",
    "    avg_acc_mean = np.sum(avg_acc*(total_counts/np.sum(total_counts)))\n",
    "    total_counts_mean = np.sum(total_counts)\n",
    "        \n",
    "    print(\"------\")\n",
    "    print(\"Avg. loss of all \"+(\"smooth\" if label==0 else \"rough\")+\" objects: \\t\"+str(np.round(avg_loss_mean,4)))\n",
    "    print(\"Avg. accuracy of all \"+(\"smooth\" if label==0 else \"rough\")+\" objects: \\t\"+str(np.round(avg_acc_mean,4)))\n",
    "    print(\"Total chunks of all \"+(\"smooth\" if label==0 else \"rough\")+\" objects: \\t\"+str(total_counts_mean))\n",
    "    \n",
    "    return avg_loss_mean, avg_acc_mean, total_counts_mean\n",
    "\n",
    "\n",
    "smooth_stats = test_files(folder,smooth_stones_test,0)\n",
    "rough_stats = test_files(folder,rough_stones_test,1)\n",
    "\n",
    "print(\"\\n#################################################\\nConfusion Matrix:\\n\")\n",
    "chunks_total = smooth_stats[2]+rough_stats[2]\n",
    "\n",
    "fp = (1-smooth_stats[1]) * smooth_stats[2] / chunks_total\n",
    "tp = rough_stats[1] * rough_stats[2] / chunks_total\n",
    "fn = (1-rough_stats[1]) * rough_stats[2] / chunks_total\n",
    "tn = smooth_stats[1] * smooth_stats[2] / chunks_total\n",
    "\n",
    "print(\"fp\",fp,\"tp\",tp,\"fn\",fn,\"tn\",tn)\n",
    "print(\"sum:\",np.sum([fp,tp,fn,tn]),\"chunks_total\",chunks_total)\n",
    "\n",
    "print(\"\\n#################################################\\nTesting final runs:\\n\")\n",
    "\n",
    "smooth_runs = []\n",
    "smooth_runs.append(test_file(\"./roughness_dataset/finals_recordings/\",\"day_1_smooth.wav\",0,None))\n",
    "smooth_runs.append(test_file(\"./roughness_dataset/finals_recordings/\",\"day_2_smooth.wav\",0,None))\n",
    "smooth_runs = np.asarray(smooth_runs)\n",
    "\n",
    "rough_runs = []\n",
    "rough_runs.append(test_file(\"./roughness_dataset/finals_recordings/\",\"day_1_rough.wav\",1,None))\n",
    "rough_runs.append(test_file(\"./roughness_dataset/finals_recordings/\",\"day_2_rough.wav\",1,None))\n",
    "rough_runs = np.asarray(rough_runs)\n",
    "\n",
    "rough_chunks = np.sum(rough_runs[:,2])\n",
    "smooth_chunks = np.sum(smooth_runs[:,2])\n",
    "total_chunks = rough_chunks+smooth_chunks\n",
    "\n",
    "rough_loss = np.sum(rough_runs[:,0] * (rough_runs[:,2] / rough_chunks))\n",
    "rough_accuracy = np.sum(rough_runs[:,1] * (rough_runs[:,2] / rough_chunks))\n",
    "print(\"\\nrough_loss\",rough_loss,\"\\trough_accuracy\",rough_accuracy)\n",
    "\n",
    "smooth_loss = np.sum(smooth_runs[:,0] * (smooth_runs[:,2] / smooth_chunks))\n",
    "smooth_accuracy = np.sum(smooth_runs[:,1] * (smooth_runs[:,2] / smooth_chunks))\n",
    "print(\"smooth_loss\",smooth_loss,\"\\tsmooth_accuracy\",smooth_accuracy)\n",
    "\n",
    "print(\"\\n#################################################\\nConfusion Matrix:\\n\")\n",
    "\n",
    "fp = (1-smooth_accuracy) * smooth_chunks / total_chunks\n",
    "tp = rough_accuracy * rough_chunks / total_chunks\n",
    "fn = (1-rough_accuracy) * rough_chunks / total_chunks\n",
    "tn = smooth_accuracy * smooth_chunks / total_chunks\n",
    "\n",
    "print(\"fp\",fp,\"tp\",tp,\"fn\",fn,\"tn\",tn)\n",
    "print(\"sum:\",np.sum([fp,tp,fn,tn]),\"total_chunks\",total_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
